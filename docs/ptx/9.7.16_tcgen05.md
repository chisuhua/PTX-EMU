# 9.7.16 TensorCore 5th Generation（`tcgen05.*`）指令索引

> 章节对照：https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#tensorcore-5th-generation-instructions  
> 说明：本文件为**简明索引 + 关键约束**，完整语义以官方文档为准。

## 快速索引（本节覆盖指令）
- 分配/释放：`tcgen05.alloc`, `tcgen05.dealloc`, `tcgen05.relinquish_alloc_permit`
- 加载：`tcgen05.ld`, `tcgen05.ld.red`
- 计算：`tcgen05.mma`, `tcgen05.mma.sp`, `tcgen05.mma.ws`, `tcgen05.mma.ws.sp`
- 通信/移位：`tcgen05.cp`, `tcgen05.shift`
- 完成与有序性：`tcgen05.commit`, `tcgen05.fence::*`

---

# NVIDIA PTX 第五代 TensorCore 指令族（`tcgen05.*`）规范  
*基于 PTX ISA 9.1（Blackwell 架构）*

---

## 一、概述

第五代 TensorCore（TensorCore Gen5）指令族（`tcgen05.*`）为 Blackwell GPU 架构（如 `sm_110`, `sm_110a`, `sm_110f`）提供高吞吐、低延迟的张量计算能力。其核心特性包括：

- **显式 Tensor Memory 管理**
- **异步执行模型**
- **CTA Pair 协作通信**
- **Descriptor-based 计算抽象**
- **与 mbarrier 集成的完成跟踪机制**

> **适用架构**：`sm_100a/f`, `sm_101a/f` 及更高（官方归为 Blackwell 家族，常称 `sm_110+`）  
> **文档依据**：PTX ISA 9.1, Section 9.7.16

---

## 二、通用约束与编程模型

### 2.1 CTA Group 一致性要求
所有 `tcgen05` 指令必须使用相同的 `.cta_group::N` 限定符（`N` 为整数，通常为 `1`），用于标识参与协同的 CTA 组。  
违反此规则将导致未定义行为（见 9.7.16.8）。

### 2.2 执行模型
- 所有 `tcgen05` 指令均为 **asynchronous**（异步发射），但部分指令维持 **in-order execution**（程序顺序）。
- 异步操作的完成需通过：
  - `tcgen05.commit` + `mbarrier`（用于 `mma`, `cp`, `shift`）
  - 程序依赖或 `tcgen05.fence`（用于 `ld`）

### 2.3 内存一致性
- 跨线程/CTA 的 `tcgen05` 操作顺序必须通过：
  ```ptx
  tcgen05.fence::before_thread_sync;  // 确保此前 async 操作在 sync 前完成
  bar.sync ...;                       // 或 mbarrier.arrive
  tcgen05.fence::after_thread_sync;   // 确保此后 async 操作在 sync 后开始
  ```
  （见 9.7.16.11）

---

## 三、指令分类与规范

### 3.1 Tensor Memory 分配与管理（In-Order, Potentially Blocking）

> **说明**：这些指令按程序顺序执行，若资源不可用则阻塞（见 9.7.16.7）。

| 指令 | 语法 | 描述 |
|------|------|------|
| `tcgen05.alloc` | `tcgen05.alloc.cta_group::N.sync.aligned{.shared::cta}.b32 [dst], nCols;` | 在 Tensor Memory 中分配 `nCols` 列（32 ≤ `nCols` ≤ 512，且为 2 的幂）。分配地址写入 `[dst]`（必须位于 `.shared::cta` 地址窗口）。 |
| `tcgen05.dealloc` | `tcgen05.dealloc.cta_group::N.sync.aligned.b32 taddr, nCols;` | 释放由 `alloc` 分配的区域（`taddr` 来自 `alloc` 写入的地址）。Kernel 退出前必须释放所有分配。 |
| `tcgen05.relinquish_alloc_permit` | `tcgen05.relinquish_alloc_permit.cta_group::N.sync.aligned;` | 当前 CTA 放弃未来分配权限。此后任何 `alloc` 调用非法。 |

> **约束**：
> - `nCols` 在执行顺序中必须 **非递增**。
> - 所有指令必须使用与 kernel 中其他 `tcgen05` 指令相同的 `.cta_group::N`。

---

### 3.2 Tensor Memory 加载指令（Asynchronous）

> **说明**：所有加载指令必须包含 `.sync` 和 `.aligned` 限定符，保证 warp 内同步（见 9.7.16.3）。

| 指令 | 语法（简化） | 描述 |
|------|--------------|------|
| `tcgen05.ld` | `tcgen05.ld.sync.aligned.shape.num.cta_group::N {r}, [taddr]{, immHalfSplitoff};` | 从 Tensor Memory 加载数据到寄存器列表 `{r}`（32-bit 通用寄存器，如 `{%r1,%r2,...}`）。• `.shape`：如 `.16x32bx2`, `.16x128b`（见 Table 47）• `.num`：重复次数（1–4） |
| `tcgen05.ld.red` | `tcgen05.ld.red.redOp.sync.aligned.shape.num.cta_group::N redVal, [taddr];` | 带规约的加载（如 `.add`, `.max`），结果写入单个寄存器 `redVal`。 |

> **注意**：
> - 不支持 `.shared::cluster` 等标准地址空间修饰符。
> - 目标寄存器为 `%r`（32-bit），即使加载 FP16 数据。
> - 无需显式 `wait`；可见性由程序依赖或 fence 保证。

---

### 3.3 Tensor 计算指令（Asynchronous）

> **说明**：所有 MMA 指令使用 descriptor 指定输入/输出布局（见 9.7.16.4）。

| 指令 | 语法（简化） | 描述 |
|------|--------------|------|
| `tcgen05.mma` | `tcgen05.mma.cta_group::N.shape [taddr], adesc, bdesc, idesc, pred;` | 标准密集矩阵乘加（MMA）。 |
| `tcgen05.mma.sp` | `tcgen05.mma.sp.cta_group::N.shape [taddr], adesc, bdesc, idesc, pred;` | 稀疏 MMA（2:4 结构化稀疏）。 |
| `tcgen05.mma.ws` | `tcgen05.mma.ws.cta_group::N.shape [taddr], adesc, bdesc, idesc, pred;` | Weight-Stationary（权重驻留）模式。 |
| `tcgen05.mma.ws.sp` | `tcgen05.mma.ws.sp.cta_group::N.shape [taddr], adesc, bdesc, idesc, pred;` | 稀疏 + 权重驻留 MMA。 |

> **操作数说明**：
> - `adesc`, `bdesc`：A/B 片段描述符（来自 `ld` 或 peer `cp`）
> - `idesc`：累加器初始化描述符
> - `pred`：谓词寄存器（控制执行）
> - `[taddr]`：可选 Tensor Memory 地址（用于某些 shape）

---

### 3.4 Tensor 数据移动指令（Asynchronous）

| 指令 | 语法 | 描述 |
|------|------|------|
| `tcgen05.cp` | `tcgen05.cp.cta_group::N.shape [taddr], sdesc;` | 从 peer CTA 的 Tensor Memory 拷贝数据（见 9.7.16.10）。• `sdesc`：源描述符（由 peer CTA 生成）• 必须指定 `.shape` |
| `tcgen05.shift` | `tcgen05.shift.cta_group::N;` | 在 CTA 内或 CTA Pair 间循环移位张量数据（用于 GEMM 分块通信）。 |

> **注意**：`tcgen05.st` **不存在于 PTX ISA 9.1**。

---

### 3.5 完成跟踪与同步指令（Asynchronous）

| 指令 | 语法 | 描述 |
|------|------|------|
| `tcgen05.commit` | `tcgen05.commit.cta_group::N.mbarrier::arrive::one{.shared::cluster}{.multicast}.b64 [mbar] {, ctaMask};` | 将此前所有 `mma`/`cp`/`shift` 操作关联到 mbarrier。完成后触发 `mbarrier.arrive`。 |
| `tcgen05.fence::before_thread_sync` | `tcgen05.fence::before_thread_sync;` | 确保此前所有 `tcgen05` 操作在后续线程同步前完成。 |
| `tcgen05.fence::after_thread_sync` | `tcgen05.fence::after_thread_sync;` | 确保此后所有 `tcgen05` 操作在先前线程同步后开始。 |

> **重要**：`tcgen05.wait::ld` / `tcgen05.wait::st` **不存在**。

---

## 四、高级编程语义

### 4.1 CTA Pair 通信模型（9.7.16.10）
- 每两个连续 CTA（ID 为 `2k` 和 `2k+1`）组成一个 **CTA Pair**。
- `tcgen05.cp` 和 `tcgen05.shift` 可在 pair 内交换数据。
- 所有参与 CTA 必须使用相同 `.cta_group::N`。

### 4.2 指令排序与 Pipeline（9.7.16.9）
尽管 `tcgen05` 指令异步执行，以下指令对保证 **程序顺序执行**：
- `tcgen05.cp` → `tcgen05.mma`（相同 `.cta_group::N`）
- `tcgen05.shift` → `tcgen05.mma`
- `tcgen05.mma` → `tcgen05.shift`
- `tcgen05.mma` → `tcgen05.commit`

> 此外，`tcgen05.ld` 与其后续依赖指令也维持顺序。

### 4.3 内存一致性（9.7.16.11）
- 异步操作对其他线程不可见，除非：
  - 使用 `tcgen05.commit` + `mbarrier.wait`
  - 使用 `tcgen05.fence` + 标准同步原语（`bar.sync`, `mbarrier`）

---

## 五、开发建议（Best Practices）

1. **始终使用一致的 `.cta_group::N`**（通常为 `1`）。
2. **`alloc` 后必须 `dealloc`**，避免资源泄漏。
3. **异步计算后插入 `commit` + `mbarrier.wait`** 以确保结果可见。
4. **跨 CTA 同步时，务必使用 `fence::before/after_thread_sync`**。
5. **避免在 `relinquish_alloc_permit` 后调用 `alloc`**。

---

## 六、附录：官方指令存在性确认表

| 指令 | 存在于 PTX ISA 9.1? | 同步性 | 备注 |
|------|---------------------|--------|------|
| `tcgen05.alloc` | ✅ | In-order (blocking) | 需 `.sync.aligned` |
| `tcgen05.dealloc` | ✅ | In-order | 需匹配 `alloc` 的 `nCols` |
| `tcgen05.relinquish_alloc_permit` | ✅ | In-order | 一次性操作 |
| `tcgen05.ld` | ✅ | Asynchronous | 需 `.sync.aligned.shape.num` |
| `tcgen05.ld.red` | ✅ | Asynchronous | 支持 `.add`, `.max` 等 |
| `tcgen05.mma` / `.sp` / `.ws` / `.ws.sp` | ✅ | Asynchronous | Descriptor-based |
| `tcgen05.cp` | ✅ | Asynchronous | Peer CTA copy |
| `tcgen05.shift` | ✅ | Asynchronous | CTA 内/间移位 |
| `tcgen05.commit` | ✅ | Asynchronous | 与 mbarrier 集成 |
| `tcgen05.fence::*` | ✅ | Asynchronous (ordering) | 用于线程同步边界 |
| `tcgen05.st` | ❌ | — | **不存在** |
| `tcgen05.wait::*` | ❌ | — | **不存在** |

---

参考：
- https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#tensorcore-5th-generation-instructions