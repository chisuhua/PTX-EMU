
# 9.7.13 同步与通信指令（Synchronization and Communication Instructions）
> 章节对照：https://docs.nvidia.com/cuda/parallel-thread-execution/index.html  
> 说明：本文件提供**指令索引 + 使用要点**，完整语义以官方文档为准。

## 快速索引（本节覆盖指令）
- CTA 同步：`bar.sync`
- 内存屏障：`membar.*`, `fence.*`
- 原子操作：`atom.*`
- Warp 规约：`redux.sync`（或同类 warp 规约指令族）
- Cluster/异步同步：`mbarrier.*`（Hopper+）

---

## 一、通用概念

### 1. 执行层次模型
PTX 基于 CUDA 执行模型，定义以下层次：
- **Warp**：32 线程的最小调度单元；warp 内线程隐式同步（无 divergent 分支时）。
- **CTA（Cooperative Thread Array）**：即 CUDA 中的 thread block；通过 `.shared` 内存通信，使用 `bar.sync` 或 `mbarrier` 同步。
- **Grid**：所有 CTA 的集合；通过全局原子或主机协调实现弱同步。
- **Cluster**（Hopper+，sm_90）：多个 CTA 的逻辑组；支持跨 CTA 同步与通信（如 `mbarrier`、`cp.async`）。

### 2. 内存一致性模型
- PTX 采用 **弱内存序（Weak Memory Ordering）**：内存操作可被重排，除非显式屏障约束。
- **两类屏障**：
  - **执行屏障（Execution Barrier）**：如 `bar.sync`，确保线程控制流同步。
  - **内存屏障（Memory Barrier）**：如 `membar`、`fence`，约束内存操作的可见性与顺序。

---

## 二、线程块内同步

### 1. `bar.sync` — CTA 同步屏障
```ptx
bar.sync b, n;
```
- **功能**：当前 CTA 中所有调用该指令的线程在此等待，直到 **恰好 `n` 个线程** 到达同一屏障 ID `b`。
- **参数**：
  - `b`：屏障 ID（0–15，sm_13+；通常为 0）
  - `n`：**必须等于实际参与该屏障调用的线程数**，且所有调用者必须使用相同的 `n`
- **行为**：
  - 若 `n` ≠ 实际到达线程数 → **未定义行为（可能死锁）**
  - 支持谓词执行（部分线程跳过），但需保证 `n` 一致
- **架构支持**：所有架构（sm_10+）
- **典型用法**：
  ```ptx
  st.shared.f32 [%r1], %f1;
  bar.sync 0, %nctaid;   // %nctaid = CTA 总线程数
  ld.shared.f32 %f2, [%r2];
  ```

> ⚠️ 注意：`bar.sync` **不提供内存排序保证**！需配合 `membar.cta` 确保共享内存可见性。

---

## 三、内存排序屏障

### 2. `membar` — 传统内存屏障
```ptx
membar.scope;
```
- **功能**：确保屏障前的所有内存操作在指定作用域内完成并对其它线程可见后，才执行后续操作。
- **作用域（scope）**：

| 作用域 | 说明 | 最小架构 |
|--------|------|----------|
| `.cta` | 同一线程块内线程 | sm_20 |
| `.gl`  | 全局内存（所有 CTA） | sm_20 |
| `.sys` | 整个系统（含主机 CPU） | sm_60 |

- **语义**：全屏障（读+写），等效于 acquire-release 组合。
- **示例**：
  ```ptx
  st.global.u32 [%rd1], %r1;
  membar.gl;               // 确保写入对其他 CTA 可见
  ld.global.u32 %r2, [%rd2];
  ```

> ❗ `membar` 不支持 `.cluster` 作用域。

---

### 3. `fence` — 现代细粒度内存排序（PTX 7.0+）
```ptx
fence.space.scope.ordering;
```
- **功能**：比 `membar` 更灵活，支持独立指定 **代理空间（proxy）**、**作用域（scope）** 和 **排序语义（ordering）**。
- **组件**：
  - **space（proxy）**：`.gpu`, `.cluster`, `.sys`
  - **scope（可选）**：`.cta`, `.cluster`
  - **ordering**：`.acquire`, `.release`, `.acq_rel`, `.relaxed`
- **合法组合示例**：
  ```ptx
  fence.gpu.release;          // release 语义，对 GPU 可见
  fence.cluster.acq_rel;      // Hopper+，跨 CTA acquire-release
  fence.sys.acquire;          // 从主机读取前同步
  ```
- **架构支持**：
  - `.gpu` / `.cta`：sm_70+
  - `.cluster`：sm_90+
  - `.sys`：sm_60+

> ✅ 推荐：在 Hopper 架构中优先使用 `fence` 替代 `membar` 以获得更优性能。

---

## 四、原子操作（Atomic Operations）

原子操作对内存地址执行不可分割的 **读-改-写（RMW）** 序列。

### 4. `atom` — 基础原子指令
```ptx
atom.space.op.type d, [addr], src;
// 或 CAS 形式：
atom.space.cas.type d, [addr], compare, swap;
```
- **地址空间（space）**：`.global`, `.shared`, `.sys`
- **操作（op）**：
  - 算术：`.add`, `.sub`
  - 位运算：`.and`, `.or`, `.xor`
  - 极值：`.min`, `.max`
  - 控制：`.exch`（交换）, `.inc`, `.dec`（环绕增减）
  - 比较交换：`.cas`
- **类型（type）**：`.s32`, `.u32`, `.u64`, `.b32`, `.b64`, `.f32`（部分操作）
- **关键变体**：

#### a. 整数加法
```ptx
atom.global.add.u32 %r1, [%rd1], 1;  // r1 = old_value; mem += 1
```

#### b. 比较并交换（CAS）
```ptx
atom.global.cas.b32 %r1, [%rd1], %compare, %swap;
// if (mem == compare) { mem = swap; r1 = compare; }
// else { r1 = mem; }
```

#### c. 浮点原子
```ptx
atom.global.add.f32 %f1, [%rd1], %f2;  // sm_20+
// f64 仅支持 .cas（sm_60+）
```

- **架构支持**：
  - `.shared` 原子：sm_20+（Fermi 起高效支持）
  - `.global` 原子：sm_12+（但 sm_20+ 性能显著提升）

> ⚠️ 限制：
> - `.f64` 仅支持 `.cas`
> - `.shared` 原子在 Volta+ 上可能退化为串行（取决于地址对齐）

---

## 五、Warp 级规约：`redux.sync`

> **取代旧版 `red` 指令**（已弃用）

### 5. `redux.sync` — Warp 内同步规约（PTX 7.0+）
```ptx
redux.sync.op.modifier.type d, a, mask;
```
- **功能**：在 warp 内对活跃线程（由 `mask` 指定）执行规约操作。
- **操作（op）**：`.add`, `.min`, `.max`, `.and`, `.or`, `.xor`
- **修饰符（modifier）**：
  - `.abs`：取绝对值（浮点）
  - `.NaN`：将 NaN 视为无穷大（浮点 min/max）
- **类型**：`.s32`, `.u32`, `.f32`（sm_100a/f+）
- **参数**：
  - `a`：源操作数
  - `mask`：32-bit lane mask（指定参与线程）
- **示例**：
  ```ptx
  mov.u32 %r1, 0xFFFFFFFF;     // 所有线程参与
  redux.sync.add.s32 %r2, %r0, %r1;
  ```
- **架构支持**：
  - 整数：sm_80+
  - 浮点（`.f32`）：sm_100a / sm_100f+

> ✅ 最佳实践：**优先使用 `redux.sync` 替代 warp 内 `atom.add.shared`**，性能更高。

---

## 六、Hopper 新特性：多 CTA 同步（Cluster-Level）

> 适用于 **Cluster 执行模型**（sm_90+）

### 6. `mbarrier` — 多 CTA 屏障对象

#### a. 初始化
```ptx
mbarrier.init.shared.b64 [addr], count;
```
- 设置屏障预期到达线程数（`count`）
- 地址位于 `.shared::cta` 空间

#### b. 到达屏障
```ptx
mbarrier.arrive.release.cluster.shared::cta.b64 [addr];
```
- 当前线程“到达”，递减计数
- `.release`：释放语义（确保之前写入对其他 CTA 可见）
- `.cluster`：作用域为 Cluster 内所有 CTA

#### c. 非阻塞等待
```ptx
mbarrier.try_wait.shared::cta.b64 p, [addr];
```
- **无超时参数**！返回布尔谓词 `p` 表示是否完成
- 用户需自行循环轮询或结合 `nanosleep`

#### d. 异步拷贝集成
```ptx
cp.async.mbarrier.arrive.release.cluster.shared::cta.b64 [addr];
```
- 异步拷贝完成后自动触发 `arrive`
- 支持 `.noinc` 修饰符（不计入 arrive 计数，用于信号）

> ⚠️ 注意：
> - `mbarrier` 对象生命周期限于 Cluster
> - `.cluster` 作用域需 sm_90+
> - 使用 `.parity` 修饰符可实现多阶段同步（见官方文档）

---

## 七、其他同步指令

### 7. `griddepcontrol` — Grid 依赖控制（PTX 7.0+）
```ptx
griddepcontrol.launch_dependents;
griddepcontrol.wait;
```
- 用于 **父子 grid 启动依赖**（如 CUDA Graphs）
- 极少直接使用，通常由运行时管理

### 8. `red` — 旧版规约（已弃用）
- **PTX 7.0 起正式弃用**
- **完全由 `redux.sync` 取代**

---

## 八、作用域与架构支持总表

| 指令 | 作用域 | 最小架构 | 用途 |
|------|--------|----------|------|
| `bar.sync` | CTA | sm_10 | CTA 内执行同步 |
| `membar.cta` | CTA | sm_20 | 共享内存排序 |
| `membar.gl` | Grid | sm_20 | 全局内存排序 |
| `membar.sys` | System | sm_60 | 主机-GPU 一致性 |
| `fence.gpu.release` | CTA/Grid | sm_70 | 细粒度内存排序 |
| `fence.cluster.acq_rel` | Cluster | sm_90 | 跨 CTA 同步 |
| `atom.global` | Grid | sm_12 | 全局原子 RMW |
| `atom.shared` | CTA | sm_20 | 共享原子（谨慎使用）|
| `redux.sync` | Warp | sm_80 | 高效 warp 规约 |
| `mbarrier.*` | Cluster | sm_90 | 多 CTA 同步 |
| `griddepcontrol` | Grid | sm_70 | Grid 间依赖 |

---

## 九、典型应用场景

### 1. 共享内存生产者-消费者
```ptx
// Producer
st.shared.f32 [%r1], %f1;
membar.cta;           // 确保写入可见
bar.sync 0, %nctaid;  // 同步执行

// Consumer
bar.sync 0, %nctaid;
ld.shared.f32 %f2, [%r2];
```

### 2. 全局计数器
```ptx
atom.global.add.u32 %r1, [%counter], 1;
```

### 3. 无锁队列（CAS 自旋）
```ptx
try_push:
    ld.global.u32 %head, [%queue_head];
    add.u32 %new_head, %head, 1;
    atom.global.cas.b32 %old, [%queue_head], %head, %new_head;
    setp.ne.u32 p0, %old, %head;
    @p0 bra try_push;
```

### 4. Hopper 异步加载 + mbarrier 同步
```ptx
// 初始化 mbarrier（count = 1）
mbarrier.init.shared.b64 [mb], 1;

// 异步拷贝并自动 arrive
cp.async.ca.shared.global [dst], [src], 16;
cp.async.mbarrier.arrive.release.cluster.shared::cta.b64 [mb];

// 等待数据就绪
wait_loop:
    mbarrier.try_wait.shared::cta.b64 p, [mb];
    @!p nanosleep.u32 100;
    @!p bra wait_loop;
```

---

## ✅ 最佳实践总结

- **共享内存访问后**：使用 `membar.cta` + `bar.sync` 确保可见性与同步。
- **避免共享内存原子**：优先用 `redux.sync`（warp 内）或重新设计算法。
- **全局原子慎用**：高争用下性能急剧下降；考虑局部聚合。
- **Hopper 架构**：
  - 使用 `mbarrier` + `cp.async` 实现计算-通信重叠
  - 用 `fence.cluster.acq_rel` 替代 `membar.gl` 获得更优性能
- **绝不使用 `membar.sys` 除非必要**：性能极低（涉及 CPU 缓存一致性）。
- **始终匹配架构能力**：检查 sm 版本再使用新特性（如 `redux.sync.f32` 需 sm_100a/f）。

---

参考：
- https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions

--- 

如需严格语义与边界条件，请以官方文档为准。