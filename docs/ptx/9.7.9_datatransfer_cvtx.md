
# 9.7.9 数据移动与转换指令（Data Movement and Conversion Instructions）详解  
> **依据**：[NVIDIA PTX ISA 9.1 官方文档](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions)  
> **覆盖架构**：sm_10 至 sm_120（Blackwell）

本节全面阐述 GPU 编程中用于 **寄存器操作、内存访问、地址转换、数值类型变换及异步数据传输** 的核心 PTX 指令。这些指令是实现高性能计算、低精度 AI 训练、内存优化及硬件特性利用的基础。


## 一、通用规则

### 1. 内存空间限定符（Memory Space Qualifiers）
所有显式内存访问指令（`ld`, `st`, `atom`, `red` 等）必须指定地址空间：
- `.global`：全局内存（GPU DRAM）
- `.shared`：共享内存（CTA 内线程共享）
- `.local`：本地内存（线程私有栈/溢出区）
- `.const`：常量内存（只读，广播缓存）
- `.param`：参数内存（内核启动参数或函数参数）
- `.generic`：通用地址空间（运行时解析，性能较低）

> **注意**：`.surf` / `.tex` 属于**纹理/表面指令集**（Section 9.7.10–9.7.11），不在此节。

### 2. 向量类型（Vector Types）
- 支持 `.v2`, `.v4` 向量（如 `.v4.f32` 表示 4×float）
- **对齐要求**：
  - `.v2`：8 字节对齐
  - `.v4`：16 字节对齐
- **寄存器语法**：`{reg0, reg1, ...}` 表示连续物理寄存器组

### 3. 异步拷贝模型（Asynchronous Copy Model）
- 由 **Hopper (sm_90+)** 引入，通过 `cp.async` 系列指令实现
- 核心机制：`commit_group` → 计算重叠 → `wait_group`/`wait_all`
- 支持 **mbarrier** 和 **async-group** 两种完成机制


## 二、寄存器与位级操作

### 1. `mov` — 寄存器间位模式复制
```ptx
mov.type d, a;
```
- **功能**：**无转换**地复制位模式（bitwise copy）
- **支持类型**：`.b8/.b16/.b32/.b64`、整数、浮点
- **典型用途**：
  - IEEE 754 位表示提取（`mov.b32 %r, %f;`）
  - 寄存器重命名、谓词转整数
- **限制**：不支持跨位宽直接移动（如 `.b32` → `.b64` 需两条指令）

### 2. `shfl.sync` — Warp 内 Shuffle（同步）
```ptx
shfl.sync.{up|down|bfly|idx}.b32 d, a, b, c;
```
- **功能**：Warp 内线程直接交换寄存器值，**绕过共享内存**
- **掩码 `c`**：指定 active 线程集合（通常 `0xFFFFFFFF`）
- **架构要求**：sm_30+
- **弃用警告**：旧版 `shfl`（无 `.sync`）已废弃

### 3. `prmt` — 字节重排（Permute）
```ptx
prmt.b32 d, a, b, c;
```
- **控制字 `c`**：每 nibble 指定输出字节来源：
  - `0–3`：`a` 的字节 0–3
  - `4–7`：`b` 的字节 0–3
  - `8–F`：常量 0
- **用途**：通道重排、SIMD 打包/解包


## 三、内存加载（Load）

### 4. `ld` — 基础加载
```ptx
ld.space[.vector].type d, [addr];
```
- **变体**：
  - `ld.global.nc`：Non-coherent load（绕过 L1，sm_60+）
  - `ldu.global`：**向后兼容**的未对齐加载（sm_1x），现代架构中等价于 `ld`，**不推荐新代码使用**
- **对齐**：标量自然对齐；向量需 8/16B 对齐

### 5. `prefetch` / `prefetchu` — 预取提示
```ptx
prefetch.global.L1 [addr];
prefetch.global.L2::evict_normal [addr];
prefetchu.L1 [addr];
```
- **级别**：`.L1`, `.L2`
- **策略**：`::evict_last`（保留）, `::evict_normal`（正常替换）
- **`prefetchu`**：预取至 **uniform cache**（用于 warp-uniform 地址）
- **注意**：仅为 **hint**，硬件可忽略


## 四、内存存储（Store）

### 6. `st` — 基础存储
```ptx
st.space[.vector].type [addr], src;
```
- **重要澄清**：**PTX 中不存在 `st.async` 指令**。异步写入仅通过 `cp.async` 实现。
- **Blackwell 新增**：
  - `st.bulk`：用于 TMA（Tensor Memory Accelerator）的批量存储
  - `st.bulk.tensor`：配合 tensormap 的张量存储

---

## 五、多实例内存（Multimem）指令（Hopper+, sm_90+）

> 利用独立内存通道提升带宽，**仅用于特定规约/加载场景**

| 指令 | 功能 | 示例 |
|------|------|------|
| `multimem.ld_reduce` | 带规约语义的加载 | `multimem.ld_reduce.add.v4.f32 d, [addr];` |
| `multimem.st` | 多通道存储 | `multimem.st.relaxed.gpu.v2.f16 [addr], {r0,r1};` |
| `multimem.red` | 多通道原子规约 | `multimem.red.release.cta.global.add.f32 [addr], val;` |

- **支持的数据类型**：`.e5m2`, `.e4m3` 及其向量形式（`.x2`, `.x4`）
- **架构要求**：sm_100a/f, sm_110a/f, sm_120a/f 等 Hopper+ 架构

> **关键澄清**：**不存在 `multimem.cp.async` 指令**。异步拷贝与 multimem 是两个独立指令族。


## 六、地址空间操作

### 7. `isspacep` — 查询地址空间
```ptx
isspacep.space p, addr;
```
- **功能**：检查 `addr` 是否属于 `.space`，结果存入谓词寄存器 `p`

### 8. `cvta` — 转换通用地址
```ptx
cvta.to_space.u64 d, a;
```
- **功能**：将通用地址（generic address）转为特定空间地址
- **用途**：在 UVA（统一虚拟地址）模型中明确地址语义

### 9. `mapa` — 地址映射（Map Address）
```ptx
mapa.u64 d, a, b;
```
- **功能**：计算 `a + b` 作为 64 位地址（用于大地址模型）


## 七、类型转换（Conversion）— `cvt` 指令族

`cvt` 是 PTX 中最复杂的指令之一，支持**整数↔整数、浮点↔整数、浮点↔浮点**的全组合转换，并提供丰富的修饰符。

### 10. 基础语法
```ptx
cvt[.rnd][.sat][.ftz].dst_type.src_type d, a[, imm];
```

### 11. 舍入模式（Rounding Modifiers）

#### A. 浮点 ↔ 整数（必须指定舍入）
| 修饰符 | 行为 |
|--------|------|
| `.rn` | Round to nearest, ties to even |
| `.rz` | Round towards zero |
| `.rm` | Round towards minus infinity |
| `.rp` | Round towards plus infinity |
| **`.rs`** | **Stochastic rounding**（随机舍入，sm_80+）|

> **`.rs` 说明**：舍入结果为概率性整数，用于减少量化偏差，是 FP8 训练的关键技术。

#### B. 整数 ↔ 整数（可选舍入）
| 修饰符 | 行为 |
|--------|------|
| **`.rni`** | Round to nearest even (**for integers**) |
| **`.rzi`** | Round towards zero |
| **`.rmi`** | Round towards minus infinity |
| **`.rpi`** | Round towards plus infinity |

> **特殊语法**：整数转换可带立即数缩放因子（如 `cvt.rni.s32.s32 d, a, 4;` 表示右移4位后舍入）

### 12. 其他修饰符
- `.sat`：饱和（溢出时钳位到目标类型范围）
- `.ftz`：Flush subnormal to zero（仅浮点）

### 13. 打包转换（Pack Conversions）
```ptx
cvt.pack[.sat].dst_vec.src_type d, a, b;
```
- **功能**：将两个 `src_type` 值转换、饱和、打包为一个向量
- **示例**：
  ```ptx
  cvt.pack.sat.s8.s16 %r1, %r2, %r3; // 两个 s16 → 两个 s8（打包为 s16）
  ```


## 八、异步拷贝（Asynchronous Copy）— Hopper+ 核心特性

### 14. 基础异步拷贝
```ptx
cp.async[.ca|.cg].dst_space.src_space [dst], [src], size;
```
- **缓存策略**：
  - `.ca`（cache all）：可缓存于 L1+L2
  - `.cg`（cache global）：仅缓存于 L2
- **内存顺序**：通过 `.relaxed`/`.acquire`/`.release` 指定（如 `cp.async.ca.shared.acquire.cta.global`）

### 15. Bulk & Tensor 异步拷贝（Blackwell+）
| 指令 | 功能 |
|------|------|
| `cp.async.bulk` | 批量异步拷贝（TMA） |
| `cp.async.bulk.tensor` | 张量异步拷贝（需 tensormap） |
| `cp.reduce.async.bulk` | 带规约的批量拷贝 |
| `cp.async.bulk.prefetch` | 预取 tensormap |

### 16. 完成与同步
```ptx
cp.async.commit_group;      // 提交当前 group
cp.async.wait_group N;      // 等待第 N 个 group
cp.async.wait_all;          // 等待所有 group（新增！）
```

> **编程模型**：发起 → commit → 计算 → wait


## 九、其他指令（按官方文档归类）

### 17. 缓存控制（Cache Control）
- `discard`：丢弃缓存行（sm_80+）
- `applypriority`：**不存在于官方文档**（应为误解）
- `createpolicy`：实验性缓存策略（ISA 8.8+），非主干指令

> **建议**：将 `discard` 移至“缓存控制”附录，非本节核心。

### 18. 特殊指令（非本节核心，应移出）
- `getctarank`：属于 **Special Register Instructions**（Section 9.7.1）
- `nanosleep`：属于 **Control Flow Instructions**（Section 9.7.12）


## 十、总结表：核心指令速查

| 类别 | 指令 | 关键特性 | 架构要求 |
|------|------|--------|--------|
| **寄存器操作** | `mov`, `shfl.sync`, `prmt` | 位复制、warp shuffle、字节重排 | sm_30+ |
| **内存访问** | `ld`/`st`（含 `.nc`, `.bulk`） | 对齐、向量、TMA | sm_20+ / sm_120+ |
| **地址操作** | `cvta`, `isspacep`, `mapa` | 地址空间转换与查询 | sm_20+ |
| **类型转换** | `cvt`（含 `.rs`, `.rni`, `.pack`）| 舍入、饱和、随机舍入、打包 | sm_10+ / sm_80+ |
| **异步拷贝** | `cp.async.*` | commit/wait, bulk, tensor | sm_90+ |
| **高级内存** | `multimem.*` | 多通道规约加载/存储 | sm_90+ |
| **预取** | `prefetch`/`prefetchu` | L1/L2 预取 hint | sm_20+ |

---

## ✅ 最佳实践与注意事项

1. **避免 `ldu`**：仅用于遗留代码，新项目统一用 `ld`。
2. **`st.async` 不存在**：异步写入必须用 `cp.async`。
3. **浮点→整数必加舍入**：否则 PTX 编译失败。
4. **AI 量化优先用 `.rs`**：随机舍入显著提升低精度训练稳定性。
5. **Hopper 上广泛使用 `cp.async`**：可隐藏 70%+ 内存延迟。
6. **Blackwell 使用 `st.bulk`/`cp.async.bulk`**：充分发挥 TMA 带宽。

---

参考：
- https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions

---

如需严格语义与边界条件，请以官方文档为准。